# Unsupervised Jobâ€“Candidate Matching System with Explainable AI

Lâ€™objectif est de construire un systÃ¨me intelligent de **matching entre CV et offres dâ€™emploi**, capable de :

- Calculer un **score de compatibilitÃ©** entre le profil du candidat et les offres disponibles
- Classer les rÃ©sultats en :
  - `Highly Compatible`
  - `Moderately Compatible`
  - `Low Compatibility`
- Fournir **des explications claires** sur les incompatibilitÃ©s
- DÃ©ployer une application complÃ¨te avec **FastAPI** pour le backend et **React** pour le frontend
- Suivre les expÃ©rimentations via **MLflow** et dÃ©ployer lâ€™application avec **Docker**

  
---

## ðŸ—‚ï¸ Datasets utilisÃ©s

1. **Hugging Face â€“ Data Science Job Salaries**  
   - Salaires, expÃ©rience, pays, remote ratio, company size  
   - Lien : [huggingface.co/datasets/hugginglearners/data-science-job-salaries](https://huggingface.co/datasets/hugginglearners/data-science-job-salaries)

2. **Kaggle â€“ Job Listings Dataset**  
   - Titre des postes, compÃ©tences, descriptions, types de contrats  

3. **Scraping Ã©thique** sur **Indeed / Adzuna / Jooble API**  
   - Job title, location, salary, skills keywords  
   - Respect strict de `robots.txt` et des conditions dâ€™utilisation

> Les datasets sont fusionnÃ©s et normalisÃ©s pour crÃ©er le dataset final exploitable par le modÃ¨le.

---

## ðŸ§  MÃ©thodologie

### 1. PrÃ©processing
- Nettoyage du texte (CV et description des jobs)
- Vectorisation : TF-IDF et Sentence-BERT embeddings
- Extraction des compÃ©tences (skills) et des niveaux dâ€™expÃ©rience

### 2. ModÃ©lisation non supervisÃ©e
- **SimilaritÃ© cosinus** pour mesurer la proximitÃ© CV â†” Jobs
- **Clustering (KMeans / Agglomerative)** pour regrouper les candidats et jobs similaires
- **Anomaly Detection (Isolation Forest)** pour dÃ©tecter les CV trÃ¨s Ã©loignÃ©s du cluster cible
- **Scoring de compatibilitÃ©** :  
  - `>0.75` â†’ Highly Compatible  
  - `0.45â€“0.75` â†’ Moderately Compatible  
  - `<0.45` â†’ Low Compatibility

### 3. ExplicabilitÃ©
- Analyse des **skills manquants**
- Niveau dâ€™expÃ©rience non compatible
- Ã‰cart avec le cluster cible
- GÃ©nÃ©ration dâ€™explications automatiques pour chaque dÃ©cision

---

## Backend (FastAPI)

Endpoints principaux :
- `/health` â†’ VÃ©rifie que le service est opÃ©rationnel
- `/match_cv` â†’ Retourne les offres compatibles avec le CV soumis
- `/explain` â†’ Fournit les raisons des incompatibilitÃ©s
- `/top_jobs` â†’ Retourne les meilleures recommandations

---

## Frontend (Angular)

FonctionnalitÃ©s :
- Upload CV ou saisie dâ€™une description
- RÃ©sultats interactifs : score, dÃ©cision, explication
- Dashboard : distribution des offres, skills demandÃ©es, remote ratio
- Interface responsive et agrÃ©able

---

##  DÃ©ploiement (Docker + Docker Compose)

- Backend containerisÃ©
- Frontend containerisÃ©
- MLflow server (tracking des expÃ©riences)
- Commande de lancement :


RÃ©partition complÃ¨te des tÃ¢ches
ðŸ”¹ Week 1 â€” Foundations & Data

Objectif : Choisir les datasets, scraper les jobs, faire le nettoyage et lâ€™EDA.

TÃ¢ches de Ghada :

Choisir les datasets Hugging Face + Kaggle

Fusion et nettoyage des datasets

EDA : analyser salaires, skills, expÃ©rience

Visualisations & insights

TÃ¢ches dâ€™Anwar :

Choisir les datasets Hugging Face + Kaggle

Scraping Ã©thique des jobs

Fusion et nettoyage des datasets (support)

ðŸ”¹ Week 2 â€” NLP & Preprocessing

Objectif : Nettoyer les textes et transformer les donnÃ©es en features exploitables pour le modÃ¨le.

TÃ¢ches de Ghada :

Text cleaning (CV et offres dâ€™emploi)

Feature extraction : skills, expÃ©riences

Embeddings TF-IDF / Sentence-BERT

TÃ¢ches dâ€™Anwar :

Normalisation des colonnes

Mapping de lâ€™expÃ©rience

PrÃ©parer le dataset final pour les embeddings

ðŸ”¹ Week 3 â€” Unsupervised Modeling & MLflow

Objectif : CrÃ©er le modÃ¨le non supervisÃ©, calculer la similaritÃ©, clusterisation, anomaly detection, et suivre les expÃ©rimentations.

TÃ¢ches de Ghada :

SimilaritÃ© cosinus CV â†” Jobs

Clustering KMeans / Agglomerative

Anomaly detection (Isolation Forest)

Calcul du score de compatibilitÃ©

Suivi des expÃ©rimentations via MLflow

TÃ¢ches dâ€™Anwar :

Validation des rÃ©sultats des modÃ¨les

Documentation des rÃ©sultats et insights

ðŸ”¹ Week 4 â€” Backend FastAPI

Objectif : DÃ©velopper lâ€™API pour exposer les modÃ¨les et les rÃ©sultats.

TÃ¢ches de Ghada :

ImplÃ©menter la logique ML dans lâ€™API (calcul des scores et explications)

Logs et monitoring des endpoints

TÃ¢ches dâ€™Anwar :

DÃ©veloppement endpoints /match_cv, /explain

Batch processing & validation des inputs

Support dans lâ€™intÃ©gration de la logique ML

ðŸ”¹ Week 5 â€” Frontend React

Objectif : CrÃ©er lâ€™interface utilisateur pour uploader CV et afficher rÃ©sultats.

TÃ¢ches de Ghada :

Validation des rÃ©sultats ML cÃ´tÃ© frontend

TÃ¢ches dâ€™Anwar :

Upload CV / formulaire description

Dashboard : compatibilitÃ© & graphiques

API calls & gestion des states

ðŸ”¹ Week 6 â€” Docker & Deployment

Objectif : Containeriser backend et frontend et tester le dÃ©ploiement complet.

TÃ¢ches de Ghada :

Dockeriser le backend

docker-compose orchestration

Tests de dÃ©ploiement

TÃ¢ches dâ€™Anwar :

Dockeriser le frontend

docker-compose orchestration

Tests de dÃ©ploiement

ðŸ”¹ Week 7 â€” Final Review & CI/CD

Objectif : PrÃ©parer la documentation, la prÃ©sentation, et automatiser avec CI/CD.

TÃ¢ches de Ghada :

RÃ©daction du README et documentation finale

PrÃ©sentation ML pipeline

Tests finaux

TÃ¢ches dâ€™Anwar :

RÃ©daction du README et documentation finale

PrÃ©sentation Frontend / UI

CI/CD GitHub Actions

Tests finaux


<img width="1536" height="1024" alt="architecture" src="https://github.com/user-attachments/assets/1d2aaa8b-e29f-441a-a8b7-ed4f693af9ab" />
